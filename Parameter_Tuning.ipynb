{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5Z_RHGJSt9HC"
      ],
      "authorship_tag": "ABX9TyMlIHe6+CSGmqIqf2ImPVrf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adichat08/Support-Vector-Classifier-for-Predicting-Survival-Likelihood-of-Hepatitis-Patients/blob/main/Parameter_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z_RHGJSt9HC"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# Parameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6Wf9zWok0Re"
      },
      "source": [
        "In this section, each model's parameters(a few selected ones) will be tuned to provide optimal performance on this particular dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBv6KyNPiaOk"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Parameter Tuning for Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YN3qUN3t0Yh",
        "outputId": "4cec39a2-7073-472a-e7c2-fe4ae85d7bce"
      },
      "source": [
        "# setting up preprocessing and the linear model in a pipeline\n",
        "log_pipe_cv = Pipeline([('preprocessing',ct),('log',LogisticRegression(random_state=42))])\n",
        "# setting up the parameter grid for the grid search\n",
        "log_param_grid = {'log__C':[0.0001,0.001,0.01,0.1,1,10,100],\n",
        "                  'log__solver':['lbfgs','liblinear','newton-cg']}\n",
        "# evaluating the results of the grid search on the different metrics\n",
        "metric_lst = ['accuracy','roc_auc','f1']\n",
        "for i in metric_lst:\n",
        "  log = LogisticRegression(random_state=42,max_iter=1000)\n",
        "  log_grid = GridSearchCV(log_pipe_cv,log_param_grid,scoring = i,cv=kfold,refit=True)\n",
        "  log_grid.fit(X_train,y_train)\n",
        "  print(\"Best parameters({}):\\n{}\".format(i,log_grid.best_params_))\n",
        "  print(\"Best score({}):\\n{}\".format(i,log_grid.best_score_))\n",
        "  print('')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters(accuracy):\n",
            "{'log__C': 1, 'log__solver': 'lbfgs'}\n",
            "Best score(accuracy):\n",
            "0.8888888888888888\n",
            "\n",
            "Best parameters(roc_auc):\n",
            "{'log__C': 0.0001, 'log__solver': 'lbfgs'}\n",
            "Best score(roc_auc):\n",
            "0.869815668202765\n",
            "\n",
            "Best parameters(f1):\n",
            "{'log__C': 1, 'log__solver': 'lbfgs'}\n",
            "Best score(f1):\n",
            "0.6495726495726495\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MRA-HgbZRK5",
        "outputId": "9b53a230-5c19-4188-bc55-b8057dbff5d8"
      },
      "source": [
        "# testing the performance of the linear model using the parameters that returned the greatest f1 average(using cross validation on the training set)\n",
        "log_pipe_cv = Pipeline([('preprocessing',ct),('log',LogisticRegression(random_state=42,C=1,solver='lbfgs'))])\n",
        "kfold = KFold(n_splits=3,shuffle=True,random_state=42)\n",
        "print(\"Cross-validation scores:\\n{}\".format(\n",
        "      cross_val_score(log_pipe_cv,X_train,y_train,cv=kfold)))\n",
        "print('Average score:\\n{}'.format(\n",
        "    cross_val_score(log_pipe_cv,X_train,y_train,cv=kfold).mean()))\n",
        "print(\"Cross-validation AUC:\\n{}\".format(\n",
        "      cross_val_score(log_pipe_cv,X_train,y_train,cv=kfold,scoring='roc_auc')))\n",
        "print('Average AUC:\\n{}'.format(\n",
        "    cross_val_score(log_pipe_cv,X_train,y_train,cv=kfold,scoring='roc_auc').mean()))\n",
        "print('F1 average:\\n{}'.format(\n",
        "    cross_val_score(log_pipe_cv,X_train,y_train,cv=kfold,scoring = 'f1').mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "[0.8974359 0.8974359 0.8974359]\n",
            "Average score:\n",
            "0.8974358974358975\n",
            "Cross-validation AUC:\n",
            "[0.81696429 0.89919355 0.82142857]\n",
            "Average AUC:\n",
            "0.8458621351766512\n",
            "F1 average:\n",
            "0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtwbJXPQmKgw"
      },
      "source": [
        "Interestingly, the best parameters for the linear model are the default ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ4KmKJBOzqL"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Parameter Tuning for Gradient Boosting Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efULqhhaO6Pm",
        "outputId": "449195f9-7145-445f-acd2-891c1396b086"
      },
      "source": [
        "# Repeating grid search process for gradient boosting classifier\n",
        "xgb_pipe_cv = Pipeline([('preprocessing',ct),('xgb',XGBClassifier(random_state=42,n_jobs=-1,))])\n",
        "xgb_param_grid = {'xgb__max_depth':[2,3,4,5],\n",
        "                  'xgb__learning_rate':[0.0001,0.001,0.01,0.1,1,10,100],\n",
        "                  'xgb__n_estimators':[50,100,200]}\n",
        "metric_lst = ['accuracy','roc_auc','f1']\n",
        "for i in metric_lst:\n",
        "  xgb = XGBClassifier(random_state=42,n_jobs=-1)\n",
        "  xgb_grid = GridSearchCV(xgb_pipe_cv,xgb_param_grid,scoring = i,cv=kfold,refit=True)\n",
        "  xgb_grid.fit(X_train,y_train)\n",
        "  print(\"Best parameters({}):\\n{}\".format(i,xgb_grid.best_params_))\n",
        "  print(\"Best score({}):\\n{}\".format(i,xgb_grid.best_score_))\n",
        "  print('')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters(accuracy):\n",
            "{'xgb__learning_rate': 1, 'xgb__max_depth': 2, 'xgb__n_estimators': 100}\n",
            "Best score(accuracy):\n",
            "0.8632478632478633\n",
            "\n",
            "Best parameters(roc_auc):\n",
            "{'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 50}\n",
            "Best score(roc_auc):\n",
            "0.8784562211981567\n",
            "\n",
            "Best parameters(f1):\n",
            "{'xgb__learning_rate': 1, 'xgb__max_depth': 2, 'xgb__n_estimators': 100}\n",
            "Best score(f1):\n",
            "0.6071428571428571\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPkKsDCMsImg"
      },
      "source": [
        "The gradient boosting model displayed comparatively poor performance on all three metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gSGK0f_iUFw"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Parameter Tuning for Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ABBcCHPsW86"
      },
      "source": [
        "Note: for the purpose of minimizing computational expense, the grid search for the neural network was run with f1 scoring only. This is because neural networks are very computationally heavy to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7PAQIvnmGgj",
        "outputId": "2ec8b9f5-b39a-4584-fbd8-f4eb543cf69a"
      },
      "source": [
        "# Repeating grid search process for multilayer preceptron\n",
        "mlp_param_grid = {'mlp__solver':['adam','lbfgs'],\n",
        "                  'mlp__hidden_layer_sizes':[(50),(50,50),(100,),(100,100),(100,100,50,25)],\n",
        "                  'mlp__activation':['relu','logistic'],\n",
        "                  'mlp__alpha':[0.00001,0.0001,0.001,0.01,0.1,1,10],\n",
        "                  'mlp__batch_size':[10,20,30,40]\n",
        "                  }\n",
        "mlp_pipe_cv = Pipeline([('preprocessing',ct),('mlp',MLPClassifier(max_iter=3000,random_state=42))])\n",
        "mlp = MLPClassifier(random_state=42,max_iter=10000)\n",
        "mlp_grid = GridSearchCV(mlp_pipe_cv,mlp_param_grid,scoring = 'f1',cv=kfold,refit=True)\n",
        "mlp_grid.fit(X_train,y_train)\n",
        "print(\"Best parameters(f1):\\n{}\".format(mlp_grid.best_params_))\n",
        "print(\"Best score(f1):\\n{}\".format(mlp_grid.best_score_))\n",
        "print('')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters(f1):\n",
            "{'mlp__activation': 'relu', 'mlp__alpha': 1e-05, 'mlp__batch_size': 30, 'mlp__hidden_layer_sizes': (100,), 'mlp__solver': 'adam'}\n",
            "Best score(f1):\n",
            "0.7039627039627039\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7SYC4SD4NPB",
        "outputId": "ab503d99-808b-4108-d001-96c77c29300d"
      },
      "source": [
        "# testing the performance of the neural network using the parameters that returned the greatest f1 average(using cross validation on the training set)\n",
        "mlp_pipe_cv = Pipeline([('preprocessing',ct),('mlp',MLPClassifier(max_iter=10000,random_state=42,activation='relu', alpha= 0.00001, batch_size= 35, hidden_layer_sizes= (100,), solver= 'adam'))])\n",
        "kfold = KFold(n_splits=3,shuffle=True,random_state=42)\n",
        "mlp = MLPClassifier(max_iter=10000,random_state=42,activation='relu', alpha= 0.00001, batch_size= 30, hidden_layer_sizes= (100,), solver= 'adam')\n",
        "print(\"Cross-validation scores:\\n{}\".format(\n",
        "      cross_val_score(mlp_pipe_cv,X_train,y_train,cv=kfold)))\n",
        "print('Average score:\\n{}'.format(\n",
        "    cross_val_score(mlp_pipe_cv,X_train,y_train,cv=kfold).mean()))\n",
        "print(\"Cross-validation AUC:\\n{}\".format(\n",
        "      cross_val_score(mlp_pipe_cv,X_train,y_train,cv=kfold,scoring='roc_auc')))\n",
        "print('Average AUC:\\n{}'.format(\n",
        "    cross_val_score(mlp_pipe_cv,X_train,y_train,cv=kfold,scoring='roc_auc').mean()))\n",
        "print('F1 average:\\n{}'.format(\n",
        "    cross_val_score(mlp_pipe_cv,X_train,y_train,cv=kfold,scoring = 'f1').mean()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "[0.92307692 0.87179487 0.92307692]\n",
            "Average score:\n",
            "0.905982905982906\n",
            "Cross-validation AUC:\n",
            "[0.75       0.81854839 0.84821429]\n",
            "Average AUC:\n",
            "0.8055875576036865\n",
            "F1 average:\n",
            "0.7039627039627039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFr0jkFmsw7k"
      },
      "source": [
        "The best parameters for the neural network don't appear to perform differently from the default at all. Many of the parameter values that the grid search returned are the same as the default values, however."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elu1OhguN5xJ"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Parameter Tuning for SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSZ1A01Locug",
        "outputId": "d410c63c-b5b9-4c1a-cb6c-f6625487f26e"
      },
      "source": [
        "# Repeating grid search process for support vector machine\n",
        "svc_param_grid = [{'svm__C':[0.001,0.01,0.1,1,10,100],\n",
        "                   'svm__kernel':['rbf','poly','sigmoid'],\n",
        "                   'svm__gamma':[0.001,0.01,0.1,1,10,100,'auto','scale']},\n",
        "                  {'svm__C':[0.001,0.01,0.1,1,10,100],\n",
        "                   'svm__kernel':['linear']\n",
        "                  }]\n",
        "svc_pipe_cv = Pipeline([('preprocessing',ct),('svm',SVC(random_state=42))])\n",
        "metric_lst = ['accuracy','roc_auc','f1']\n",
        "for i in metric_lst:\n",
        "  svc = SVC(random_state=42)\n",
        "  svc_grid = GridSearchCV(svc_pipe_cv,svc_param_grid,scoring = i,cv=kfold,refit=True)\n",
        "  svc_grid.fit(X_train,y_train)\n",
        "  print(\"Best parameters({}):\\n{}\".format(i,svc_grid.best_params_))\n",
        "  print(\"Best score({}):\\n{}\".format(i,svc_grid.best_score_))\n",
        "  print('')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters(accuracy):\n",
            "{'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
            "Best score(accuracy):\n",
            "0.8974358974358975\n",
            "\n",
            "Best parameters(roc_auc):\n",
            "{'svm__C': 1, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
            "Best score(roc_auc):\n",
            "0.8590629800307218\n",
            "\n",
            "Best parameters(f1):\n",
            "{'svm__C': 100, 'svm__gamma': 0.01, 'svm__kernel': 'sigmoid'}\n",
            "Best score(f1):\n",
            "0.6868686868686869\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic7UvjdMOATO",
        "outputId": "47e3c132-4d77-45e1-ff1b-d77f1611d95d"
      },
      "source": [
        "# testing the performance of the support vector machine using the parameters that returned the greatest f1 average(using cross validation on the training set)\n",
        "svc_pipe_cv = Pipeline([('preprocessing',ct),('svm',SVC(C=100,gamma=0.01,kernel = 'sigmoid',random_state=42))])\n",
        "kfold = KFold(n_splits=3,shuffle=True,random_state=42)\n",
        "svc = SVC(C=100,gamma=0.01,random_state=42,kernel='rbf')\n",
        "print(\"Cross-validation scores:\\n{}\".format(\n",
        "      cross_val_score(svc_pipe_cv,X_train,y_train,cv=kfold)))\n",
        "print('Average score:\\n{}'.format(\n",
        "    cross_val_score(svc_pipe_cv,X_train,y_train,cv=kfold).mean()))\n",
        "print(\"Cross-validation AUC:\\n{}\".format(\n",
        "      cross_val_score(svc_pipe_cv,X_train,y_train,cv=kfold,scoring='roc_auc')))\n",
        "print('Average AUC:\\n{}'.format(\n",
        "    cross_val_score(svc_pipe_cv,X_train,y_train,cv=kfold,scoring='roc_auc').mean()))\n",
        "print('F1 average:\\n{}'.format(\n",
        "    cross_val_score(svc_pipe_cv,X_train,y_train,cv=kfold,scoring = 'f1').mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "[0.8974359  0.87179487 0.92307692]\n",
            "Average score:\n",
            "0.8974358974358975\n",
            "Cross-validation AUC:\n",
            "[0.80803571 0.8266129  0.86607143]\n",
            "Average AUC:\n",
            "0.8335733486943164\n",
            "F1 average:\n",
            "0.6868686868686869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWCT-uYq9sqU"
      },
      "source": [
        "The SVC displayed significant improvement with the selection of optimal parameters, especially when it came to the f1-score, which is the most important metric for this task."
      ]
    }
  ]
}