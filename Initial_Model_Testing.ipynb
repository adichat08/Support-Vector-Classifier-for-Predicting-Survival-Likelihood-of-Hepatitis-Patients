{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eJCLXXxFKOip"
      ],
      "authorship_tag": "ABX9TyPJslo08x6++WzGVkAKqxdF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adichat08/Support-Vector-Classifier-for-Predicting-Survival-Likelihood-of-Hepatitis-Patients/blob/main/Initial_Model_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJCLXXxFKOip"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Initial Model Testing\n",
        "Note: All preprocessing is done in a cross-validation loop. This is to avoid data leakage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6j-q-jl3zTa"
      },
      "source": [
        "--------------------------------------------\n",
        "In this section, four different models will be trained and tested on training data using three-fold cross validation.\n",
        "\n",
        "The chosen models are:\n",
        "*   A linear model(LogisticRegression)\n",
        "*   A gradient boosting machine(XGBClassifier)\n",
        "*   A multilayer preceptron(MLPClassifier)\n",
        "*   A support vector machine(SVC)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hENchvq1ydGg",
        "outputId": "f5ea9350-7093-4e1f-f2a0-6ce6ba5ab056"
      },
      "source": [
        "# looking at scikit-learn's available scoring metrics\n",
        "print(\"Scoring Metrics:\\n{}\".format(sorted(SCORERS.keys())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scoring Metrics:\n",
            "['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision', 'balanced_accuracy', 'completeness_score', 'explained_variance', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'fowlkes_mallows_score', 'homogeneity_score', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted', 'max_error', 'mutual_info_score', 'neg_brier_score', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_gamma_deviance', 'neg_mean_poisson_deviance', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'neg_root_mean_squared_error', 'normalized_mutual_info_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'rand_score', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc', 'roc_auc_ovo', 'roc_auc_ovo_weighted', 'roc_auc_ovr', 'roc_auc_ovr_weighted', 'top_k_accuracy', 'v_measure_score']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwWuWBdKZSO2"
      },
      "source": [
        "# creating a column transformer to apply the StandardScaler() om\n",
        "# the numerical columns\n",
        "ct =ColumnTransformer([(\"scaling\",StandardScaler(),['AGE','BILIRUBIN','ALK PHOSPHATE','SGOT','ALBUMIN'])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wa2LA7Jh-sF",
        "outputId": "2538c219-a68b-442e-e8aa-97bcb83d3c5f"
      },
      "source": [
        "# creating a pipeline to preprocess the data inside the cross validation(to avoid data leakage)\n",
        "log_pipe_cv = Pipeline([('preprocessing',ct),('log',LogisticRegression(random_state=42))])\n",
        "# creating a KFold object to use for the cross validation\n",
        "kfold = KFold(n_splits=3,shuffle=True,random_state=42)\n",
        "# evaluating the performance performance of the linear model(LogisticRegression) with the\n",
        "# chosen performance metrics\n",
        "print(\"Cross-validation scores:\\n{}\".format(\n",
        "      cross_val_score(log_pipe_cv,X_train,y_train,cv=kfold)))\n",
        "print('Average score:\\n{}'.format(\n",
        "    cross_val_score(log_pipe_cv,X_train,y_train,cv=kfold).mean()))\n",
        "print(\"Cross-validation AUC:\\n{}\".format(\n",
        "      cross_val_score(log_pipe_cv,X_train,y_train,cv=kfold,scoring='roc_auc')))\n",
        "print('Average AUC:\\n{}'.format(\n",
        "    cross_val_score(log_pipe_cv,X_train,y_train,cv=kfold,scoring='roc_auc').mean()))\n",
        "print('F1 average:\\n{}'.format(\n",
        "    cross_val_score(log_pipe_cv,X_train,y_train,cv=kfold,scoring = 'f1').mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores:\n",
            "[0.8974359  0.87179487 0.8974359 ]\n",
            "Average score:\n",
            "0.8888888888888888\n",
            "Cross-validation AUC:\n",
            "[0.80803571 0.89112903 0.83482143]\n",
            "Average AUC:\n",
            "0.8446620583717358\n",
            "F1 average:\n",
            "0.6495726495726495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm3Q-gGNukeX",
        "outputId": "ef6aae57-0532-4dd9-d8fe-57331dfeb4c0"
      },
      "source": [
        "# repeating the process with the gradient boosting model(XGBClassifier)\n",
        "xgb_pipe_cv = Pipeline([('preprocessing',ct),('xgb',XGBClassifier(random_state=42))])\n",
        "kfold = KFold(n_splits=3,shuffle=True,random_state=42)\n",
        "print(\"Cross-validation scores:\\n{}\".format(\n",
        "      cross_val_score(xgb_pipe_cv,X_train,y_train,cv=kfold)))\n",
        "print('Average score:\\n{}'.format(\n",
        "    cross_val_score(xgb_pipe_cv,X_train,y_train,cv=kfold).mean()))\n",
        "print(\"Cross-validation AUC:\\n{}\".format(\n",
        "      cross_val_score(xgb_pipe_cv,X_train,y_train,cv=kfold,scoring='roc_auc')))\n",
        "print('Average AUC:\\n{}'.format(\n",
        "    cross_val_score(xgb_pipe_cv,X_train,y_train,cv=kfold,scoring='roc_auc').mean()))\n",
        "print('F1 average:\\n{}'.format(\n",
        "    cross_val_score(xgb_pipe_cv,X_train,y_train,cv=kfold,scoring = 'f1').mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores:\n",
            "[0.82051282 0.87179487 0.84615385]\n",
            "Average score:\n",
            "0.8461538461538461\n",
            "Cross-validation AUC:\n",
            "[0.87946429 0.87903226 0.84375   ]\n",
            "Average AUC:\n",
            "0.8674155145929339\n",
            "F1 average:\n",
            "0.5256410256410257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqclX50iu7_Z",
        "outputId": "62b060ee-d51d-46eb-ca20-06740d082065"
      },
      "source": [
        "# repeating the process with the multilayer perceptron(MLPClassifier)\n",
        "mlp_pipe_cv = Pipeline([('preprocessing',ct),('mlp',MLPClassifier(max_iter=2000,random_state=42))])\n",
        "kfold = KFold(n_splits=3,shuffle=True,random_state=42)\n",
        "mlp = MLPClassifier(max_iter=1000,random_state=42)\n",
        "print(\"Cross-validation scores:\\n{}\".format(\n",
        "      cross_val_score(mlp_pipe_cv,X_train,y_train,cv=kfold)))\n",
        "print('Average score:\\n{}'.format(\n",
        "    cross_val_score(mlp_pipe_cv,X_train,y_train,cv=kfold).mean()))\n",
        "print(\"Cross-validation AUC:\\n{}\".format(\n",
        "      cross_val_score(mlp_pipe_cv,X_train,y_train,cv=kfold,scoring='roc_auc')))\n",
        "print('Average AUC:\\n{}'.format(\n",
        "    cross_val_score(mlp_pipe_cv,X_train,y_train,cv=kfold,scoring='roc_auc').mean()))\n",
        "print('F1 average:\\n{}'.format(\n",
        "    cross_val_score(mlp_pipe_cv,X_train,y_train,cv=kfold,scoring = 'f1').mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores:\n",
            "[0.92307692 0.87179487 0.92307692]\n",
            "Average score:\n",
            "0.905982905982906\n",
            "Cross-validation AUC:\n",
            "[0.75       0.83064516 0.85267857]\n",
            "Average AUC:\n",
            "0.8111079109062981\n",
            "F1 average:\n",
            "0.7039627039627039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZYutJklJHBo",
        "outputId": "f69a90cc-34ba-4bbd-e773-447bbf78699c"
      },
      "source": [
        "# repeating the process with the support vector machine(SVC)\n",
        "svc_pipe_cv = Pipeline([('preprocessing',ct),('svm',SVC(random_state=42))])\n",
        "kfold = KFold(n_splits=3,shuffle=True,random_state=42)\n",
        "svc = SVC(random_state=42)\n",
        "print(\"Cross-validation scores:\\n{}\".format(\n",
        "      cross_val_score(svc_pipe_cv,X_train,y_train,cv=kfold)))\n",
        "print('Average score:\\n{}'.format(\n",
        "    cross_val_score(svc_pipe_cv,X_train,y_train,cv=kfold).mean()))\n",
        "print(\"Cross-validation AUC:\\n{}\".format(\n",
        "      cross_val_score(svc_pipe_cv,X_train,y_train,cv=kfold,scoring='roc_auc')))\n",
        "print('Average AUC:\\n{}'.format(\n",
        "    cross_val_score(svc_pipe_cv,X_train,y_train,cv=kfold,scoring='roc_auc').mean()))\n",
        "print('F1 average:\\n{}'.format(\n",
        "    cross_val_score(svc_pipe_cv,X_train,y_train,cv=kfold,scoring = 'f1').mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores:\n",
            "[0.87179487 0.8974359  0.8974359 ]\n",
            "Average score:\n",
            "0.8888888888888888\n",
            "Cross-validation AUC:\n",
            "[0.81696429 0.91935484 0.82589286]\n",
            "Average AUC:\n",
            "0.8540706605222734\n",
            "F1 average:\n",
            "0.604040404040404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60vMbunr9b1N"
      },
      "source": [
        "The neural network produced the greatest accuracy, closely followed by the linear model and the SVC. The gradient boosting classifier had the lowest accuracy.\n",
        "\n",
        "When it came to AUC, the gradient boosting classifier showed the best performance. Next, the SVC returned the second best score, followed by the linear model. The neural network returned the lowest AUC score.\n",
        "\n",
        "The best f1-score came from the neural network. The linear model returned an f1 score that was slightly lower than that of the neural network, and the SVC came in third. The gradient boosting classifier had the lowest f1-score.\n",
        "\n",
        "Based on this initial cross-evaluation, the neural network and the linear model appear to be performing, on average, better than the SVC and gradient boosting classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Btqao3U5X7x_"
      },
      "source": [
        "Linear models, as implied by the name, usually model a linear relationship between features and the target. One thing that can make this linear relationship more complex is binning of certain features in the dataset. Essentially, binning will split each feature up into multiple new features, allowing the model to make a representation for each one of those new features. In this case, it is likely to add some complexity to the model, allowing it to consider many more factors about the input data when making decisions.\n",
        "\n",
        "Adding polynomial features, or powers of the original feature, can also, in many cases, help improve performance by changing the linear model's representation of a feature from a line to a curve. This will create a more complex model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ppAN2D3q4q7",
        "outputId": "15ac855e-e82b-46b0-c30e-ecb43ddf6115"
      },
      "source": [
        "# applying the column transformer to scale the data\n",
        "X_binned = ct.fit_transform(X_train)\n",
        "# creating the KBinsDiscretizer object to split each features into 5 new ones\n",
        "kb = KBinsDiscretizer(n_bins=5,strategy='quantile')\n",
        "# applying the KBinsDiscretizer object on the training data\n",
        "kb.fit(X_binned)\n",
        "X_binned = kb.transform(X_binned)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_discretization.py:197: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
            "  'decreasing the number of bins.' % jj)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTXlIXOurjOp",
        "outputId": "03096fa1-8c8e-4ec3-a5bb-3b42d9054cae"
      },
      "source": [
        "# Running a cross validation with the linear model on the binned data\n",
        "kfold = KFold(n_splits=3,shuffle=True,random_state=42)\n",
        "log = LogisticRegression(random_state=42)\n",
        "print(\"Cross-validation scores:\\n{}\".format(\n",
        "      cross_val_score(log,X_binned,y_train,cv=kfold)))\n",
        "print('Average score:\\n{}'.format(\n",
        "    cross_val_score(log,X_binned,y_train,cv=kfold).mean()))\n",
        "print(\"Cross-validation AUC:\\n{}\".format(\n",
        "      cross_val_score(log,X_binned,y_train,cv=kfold,scoring='roc_auc')))\n",
        "print('Average AUC:\\n{}'.format(\n",
        "    cross_val_score(log,X_binned,y_train,cv=kfold,scoring='roc_auc').mean()))\n",
        "print('F1 average:\\n{}'.format(\n",
        "    cross_val_score(log,X_binned,y_train,cv=kfold,scoring = 'f1').mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "[0.82051282 0.92307692 0.79487179]\n",
            "Average score:\n",
            "0.8461538461538461\n",
            "Cross-validation AUC:\n",
            "[0.875      0.86290323 0.78571429]\n",
            "Average AUC:\n",
            "0.841205837173579\n",
            "F1 average:\n",
            "0.5204795204795205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z67ZFVQlQ3a_"
      },
      "source": [
        "# adding polynomial features(degree 5) of the original dataset\n",
        "poly = PolynomialFeatures(degree=5, include_bias=False)\n",
        "poly.fit(X_binned)\n",
        "X_poly = poly.transform(X_binned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP_vtBH4PEDb",
        "outputId": "138fd15b-5ffb-4887-ac9f-cc3115733c4e"
      },
      "source": [
        "# Running a cross validation with the linear model on the data holding the polynomial features\n",
        "kfold = KFold(n_splits=3,shuffle=True,random_state=42)\n",
        "log = LogisticRegression(random_state=42,max_iter=1000,)\n",
        "print(\"Cross-validation scores:\\n{}\".format(\n",
        "      cross_val_score(log,X_poly,y_train,cv=kfold)))\n",
        "print('Average score:\\n{}'.format(\n",
        "    cross_val_score(log,X_poly,y_train,cv=kfold).mean()))\n",
        "print(\"Cross-validation AUC:\\n{}\".format(\n",
        "      cross_val_score(log,X_poly,y_train,cv=kfold,scoring='roc_auc')))\n",
        "print('Average AUC:\\n{}'.format(\n",
        "    cross_val_score(log,X_poly,y_train,cv=kfold,scoring='roc_auc').mean()))\n",
        "print('F1 average:\\n{}'.format(\n",
        "    cross_val_score(log,X_poly,y_train,cv=kfold,scoring = 'f1').mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "[0.84615385 0.82051282 0.84615385]\n",
            "Average score:\n",
            "0.8376068376068376\n",
            "Cross-validation AUC:\n",
            "[0.79017857 0.84274194 0.81696429]\n",
            "Average AUC:\n",
            "0.8166282642089094\n",
            "F1 average:\n",
            "0.4444444444444445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox9g3heVFSV_"
      },
      "source": [
        "Neither binning nor adding polynomials of the original features appear to improve the model's performance on any of the key metrics. This could be because LogisticRegression doesn't simply draw a line for its feature representations, and is likely to build more complex models than, say, LinearRegression. It's also a possibility that there is a fairly linear relationships between the features and the target."
      ]
    }
  ]
}