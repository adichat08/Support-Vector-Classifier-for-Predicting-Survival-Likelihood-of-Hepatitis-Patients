{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RDxiSaCBS6vc"
      ],
      "authorship_tag": "ABX9TyOi+W82Wx4BTZlEgO/x6BdB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adichat08/Support-Vector-Classifier-for-Predicting-Survival-Likelihood-of-Hepatitis-Patients/blob/main/Log_Transform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDxiSaCBS6vc"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# Log Transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNZFPEowZHl5"
      },
      "source": [
        "Neural networks and linear models both happen to depend heavily on the specific distribution of each attribute when making decisions. For example, if some of the feature values are enormous compared to many others, then it could make it difficult to properly train the machine learning models. Applying non-linear transformations(like a log transform) will help preserve the information that can be gathered from the data while making it easier for the model to learn from the patterns present."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tabuREMDqdLf"
      },
      "source": [
        "# applying a log transform on the columns holding continuous data(training dataset)\n",
        "X_train_log = np.log(X_train.iloc[:,:5])\n",
        "X_train_log_copy = X_train.copy()\n",
        "X_train_log_copy[['AGE','BILIRUBIN','ALK PHOSPHATE','SGOT','ALBUMIN']] = X_train_log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b48WKuBqlyq"
      },
      "source": [
        "# applying a log transform on the columns holding continuous data(test dataset)\n",
        "X_test_log = np.log(X_test.iloc[:,:5])\n",
        "X_test_log_copy = X_test.copy()\n",
        "X_test_log_copy[['AGE','BILIRUBIN','ALK PHOSPHATE','SGOT','ALBUMIN']] = X_test_log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1x-WdsvTrUH",
        "outputId": "ca1e9ae9-6047-40f8-bfbb-50ad004ba093"
      },
      "source": [
        "# Running a cross validation with the linear model on the transformed data\n",
        "# while preprocessing inside the cross validation loop\n",
        "log_pipe_cv = Pipeline([('preprocessing',ct),('log',LogisticRegression(random_state=42))])\n",
        "kfold = KFold(n_splits=3,shuffle=True,random_state=42)\n",
        "log = LogisticRegression(random_state=42)\n",
        "print(\"Cross-validation scores:\\n{}\".format(\n",
        "      cross_val_score(log_pipe_cv,X_train_log_copy,y_train,cv=kfold)))\n",
        "print('Average score:\\n{}'.format(\n",
        "    cross_val_score(log_pipe_cv,X_train_log_copy,y_train,cv=kfold).mean()))\n",
        "print(\"Cross-validation AUC:\\n{}\".format(\n",
        "      cross_val_score(log_pipe_cv,X_train_log_copy,y_train,cv=kfold,scoring='roc_auc')))\n",
        "print('Average AUC:\\n{}'.format(\n",
        "    cross_val_score(log_pipe_cv,X_train_log_copy,y_train,cv=kfold,scoring='roc_auc').mean()))\n",
        "print('F1 average:\\n{}'.format(\n",
        "    cross_val_score(log_pipe_cv,X_train_log_copy,y_train,cv=kfold,scoring = 'f1').mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "[0.87179487 0.87179487 0.84615385]\n",
            "Average score:\n",
            "0.8632478632478633\n",
            "Cross-validation AUC:\n",
            "[0.8125     0.90322581 0.81696429]\n",
            "Average AUC:\n",
            "0.8442300307219662\n",
            "F1 average:\n",
            "0.594017094017094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0clNCkQiUDor",
        "outputId": "9c9d9dd6-5484-4042-9255-9d246fee5af7"
      },
      "source": [
        "# Running a cross validation with the multilayer perceptron on the transformed data\n",
        "# while preprocessing inside the cross validation loop\n",
        "mlp_pipe_cv = Pipeline([('preprocessing',ct),('mlp',MLPClassifier(max_iter=2000,random_state=42))])\n",
        "kfold = KFold(n_splits=3,shuffle=True,random_state=42)\n",
        "mlp = MLPClassifier(max_iter=2000,random_state=42)\n",
        "print(\"Cross-validation scores:\\n{}\".format(\n",
        "      cross_val_score(mlp_pipe_cv,X_train_log_copy,y_train,cv=kfold)))\n",
        "print('Average score:\\n{}'.format(\n",
        "    cross_val_score(mlp_pipe_cv,X_train_log_copy,y_train,cv=kfold).mean()))\n",
        "print(\"Cross-validation AUC:\\n{}\".format(\n",
        "      cross_val_score(mlp_pipe_cv,X_train_log_copy,y_train,cv=kfold,scoring='roc_auc')))\n",
        "print('Average AUC:\\n{}'.format(\n",
        "    cross_val_score(mlp_pipe_cv,X_train_log_copy,y_train,cv=kfold,scoring='roc_auc').mean()))\n",
        "print('F1 average:\\n{}'.format(\n",
        "    cross_val_score(mlp_pipe_cv,X_train_log_copy,y_train,cv=kfold,scoring = 'f1').mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "[0.8974359  0.87179487 0.87179487]\n",
            "Average score:\n",
            "0.8803418803418803\n",
            "Cross-validation AUC:\n",
            "[0.75       0.78629032 0.8125    ]\n",
            "Average AUC:\n",
            "0.7829301075268816\n",
            "F1 average:\n",
            "0.6324786324786325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkuClIWJUBS5",
        "outputId": "80fb7ef5-1900-4442-8425-de115bd02dbf"
      },
      "source": [
        "# Running a cross validation with the support vector machine on the transformed data\n",
        "# while preprocessing inside the cross validation loop\n",
        "svc_pipe_cv = Pipeline([('preprocessing',ct),('svm',SVC(random_state=42))])\n",
        "kfold = KFold(n_splits=3,shuffle=True,random_state=42)\n",
        "svc = SVC(random_state=42)\n",
        "print(\"Cross-validation scores:\\n{}\".format(\n",
        "      cross_val_score(svc_pipe_cv,X_train_log_copy,y_train,cv=kfold)))\n",
        "print('Average score:\\n{}'.format(\n",
        "    cross_val_score(svc_pipe_cv,X_train_log_copy,y_train,cv=kfold).mean()))\n",
        "print(\"Cross-validation AUC:\\n{}\".format(\n",
        "      cross_val_score(svc_pipe_cv,X_train_log_copy,y_train,cv=kfold,scoring='roc_auc')))\n",
        "print('Average AUC:\\n{}'.format(\n",
        "    cross_val_score(svc_pipe_cv,X_train_log_copy,y_train,cv=kfold,scoring='roc_auc').mean()))\n",
        "print('F1 average:\\n{}'.format(\n",
        "    cross_val_score(svc_pipe_cv,X_train_log_copy,y_train,cv=kfold,scoring = 'f1').mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "[0.87179487 0.84615385 0.92307692]\n",
            "Average score:\n",
            "0.8803418803418804\n",
            "Cross-validation AUC:\n",
            "[0.88839286 0.85080645 0.78571429]\n",
            "Average AUC:\n",
            "0.8416378648233486\n",
            "F1 average:\n",
            "0.6142191142191142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxSheq67diL6"
      },
      "source": [
        "The log transform didn't appear to have a general positive impact on the performance of any of the models, per se. This could be because the data was scaled well enough when using only standardization, and nothing more was required."
      ]
    }
  ]
}